# ğŸ“Š Communication Analysis Tool for Human-AI Interaction Driving Simulator Experiments

This project is part of a screening test to analyze communication in a simulated environment. It consists of two main Python programs:

- **Data Handling & Analysis**: Transcribes and analyzes sentiment from driving simulator video files.
- **Data Understanding & Manipulation**: Visualizes transcription frequency and sentiment results using plots.


## ğŸ§ª 1. Data Handling & Analysis

This part handles:

- Importing and preprocessing video/audio files
- Performing speech-to-text transcription (using Whisper)
- Segmenting audio into 5-second chunks
- Mapping each transcription to its start timestamp
- Conducting sentiment analysis using a pre-trained transformer model (e.g., `distilbert-base-uncased-finetuned-sst-2-english`)

### Output

- Results are saved as a CSV with the following columns:
  - `chunk_id`
  - `start_time`
  - `transcription`
  - `sentiment`

â¡ï¸ **Output is saved as**: `output/transcription_<video_name>.csv`


## ğŸ“ˆ 2. Data Understanding & Visualization

This part:

- Loads a generated transcription CSV
- Generates:
  - ğŸ“Š Histogram of transcribed line frequency per 5-second bucket
  - ğŸ“ˆ Sentiment distribution plot (positive / neutral / negative)

Both plots are automatically generated and displayed using **matplotlib** and **seaborn**.


## â–¶ï¸ How to Run

### âœ… Option 1: Run Online

You can run this project directly in:

- âœ… **Kaggle Notebook**: All dependencies are pre-installed, just upload and update the dataset path.
- âœ… **Google Colab**: Upload the `.ipynb` file and mount your dataset.

No setup is required on either platform. Just upload the dataset and run the notebook cells.


### ğŸ’» Option 2: Run Locally

1. Clone this repository and download the dataset from https://alabama.app.box.com/s/vnwa6b4qi42ts39exv8jej6vzabdu78k.
2. Install dependencies: pip install -r requirements.txt

## âœ… Testing

- Tested on Kaggle using the sample video: `Experimenter_CREW_999_1_All_1731617801.mp4`
- Transcription and sentiment analysis were verified manually.
- Visual plots confirmed accurate timestamp bucketing and sentiment counts.


## ğŸ“Œ Notes

- Audio segmentation ensures each chunk is â‰¤ 5 seconds.
- Sentiment is derived from transcribed text, not tone.
- No external/proprietary API is used, only open-source models.
